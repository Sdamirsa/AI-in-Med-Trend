{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "user_query='\"Artificial Intelligence\"[Mesh]'\n",
    "user_start_date=\"2000/01/01\"\n",
    "user_end_date=\"2025/03/01\"\n",
    "user_unique_experiment_name_for_files = \"AI-in-Med-2025\"\n",
    "\n",
    "\n",
    "# In case you wanted to change the CACHE_DIRECTORY to a different location\n",
    "# import os\n",
    "# os.environ[\"CACHE_DIRECTORY\"] = \"some/folder/you/like\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If CACHE_DIRECTORY is not set, use a default path\n",
    "if \"CACHE_DIRECTORY\" not in os.environ:\n",
    "    os.environ[\"CACHE_DIRECTORY\"] = os.path.join(os.getcwd(), \"pubmed_data\")\n",
    "    print(f\"CACHE_DIRECTORY was not set, using default path {os.environ['CACHE_DIRECTORY']}\")\n",
    "elif not os.path.isabs(os.environ[\"CACHE_DIRECTORY\"]):\n",
    "    # If it's a relative path, make it absolute\n",
    "    os.environ[\"CACHE_DIRECTORY\"] = os.path.join(os.getcwd(), os.environ[\"CACHE_DIRECTORY\"])\n",
    "\n",
    "# Ensure the cache directory exists\n",
    "os.makedirs(os.environ[\"CACHE_DIRECTORY\"], exist_ok=True)\n",
    "\n",
    "# Create paths using os.path.join for better compatibility across operating systems\n",
    "S2_folder_path = os.path.join(os.environ[\"CACHE_DIRECTORY\"], \"S2_output\")\n",
    "S3_folder_path = os.path.join(os.environ[\"CACHE_DIRECTORY\"], \"S3_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1: Retriving articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code import S1_DownloadPubmed_main\n",
    "import os\n",
    "\n",
    "# S1_DownloadPubmed_main(query=user_query, start_date=user_start_date, end_date=user_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2: Cleaning XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code import create_and_copy_folder\n",
    "import os\n",
    "\n",
    "# Create S2 folder by copying from the original experiment folder\n",
    "create_and_copy_folder(source_name=os.environ[\"CACHE_DIRECTORY\"], destination_folder=S2_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code import S2_Cleaner_processor_main\n",
    "\n",
    "S2_Cleaner_processor_main(data_dir=S2_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code import S2_prepare_and_label_main\n",
    "import os\n",
    "\n",
    "S2_prepare_and_label_main(\n",
    "    folder_path= S2_folder_path,\n",
    "    filter_startstring=\"cleaned_pubmed\",\n",
    "    add_string_at_beginning=\"\"  # empty => overwrite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3: LLM-based labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code import S3_EXCT_processor_main\n",
    "# Suppose you have a dictionary of all other EXCT_main parameters:\n",
    "exct_params = {\n",
    "    \"text_key\": \"abstract\", \n",
    "    \"Pydantic_Objects_List\": [],  # your pydantic models\n",
    "    \"path_to_list\": None,\n",
    "    \"model_engine\": \"OpenAI_Async\",\n",
    "    \"parser_error_handling\": \"llm_to_correct\",\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"pre_prompt\": \"\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 2048,\n",
    "    \"logprobs\": False,\n",
    "    \"seed\": None,\n",
    "    \"timeout\": 60,\n",
    "    \"max_retries\": 2,\n",
    "    \"openai_api_key\": \"YOUR_OPENAI_API_KEY\",\n",
    "    \"runpod_base_url\": \"\",\n",
    "    \"runpod_api\": \"\",\n",
    "    \"azure_api_key\": \"YOUR_AZURE_API_KEY\",\n",
    "    \"azure_endpoint\": \"YOUR_AZURE_ENDPOINT\",\n",
    "    \"azure_api_version\": \"YOUR_AZURE_API_VERSION\",\n",
    "    \"total_async_n\": 5,\n",
    "    # Note that we don't pass json_file_path or output_file_path here\n",
    "}\n",
    "\n",
    "folder_to_process = r\"C:\\path\\to\\folder\"\n",
    "filter_str = \"processed_\"  # e.g., only process JSON files that start with \"processed_\"\n",
    "prefix_str = \"extracted_\"\n",
    "\n",
    "S3_EXCT_processor_main(\n",
    "    folder_path=folder_to_process,\n",
    "    filter_startstring=filter_str,\n",
    "    add_string_at_beginning=prefix_str,\n",
    "    EXCT_main_kwargs_dictionary=exct_params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
